---
title: "Group 11_ Assignment 5"
author: "Manya"
date: "11/16/2019"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


```{r }
library(xlsx)
library("openxlsx") 
library(rsample) 
library(dplyr) 
library(rpart) 
library(rpart.plot) 
library(ipred) 
library(caret)
library(dummies)

```

## Including Plots

You can also embed plots, for example:

```{r read_toyota, echo=FALSE}
Toyota_data<-read.xlsx("ToyotaCorolla.xlsx",sheet = "data")
Toyota_data = Toyota_data[,-1]
```

```{r display1}
Toyota_data$Fuel_Type <- factor(Toyota_data$Fuel_Type)
Toyota_data$Color <- factor(Toyota_data$Color)
```

Data Preprocessing : Create dummy variables for the categorical predictors (Fuel Type and Color). Split the data into training (50%), validation (30%), and test (20%) datasets.


```{r dummy_variables_toyota1 }
Toyota_data_new = cbind(Toyota_data,dummy(Toyota_data$Fuel_Type, sep = "_"))
Toyota_data_new$CNG <- Toyota_data_new$Toyota_data_CNG
Toyota_data_new$Petrol <- Toyota_data_new$Toyota_data_Petrol
Toyota_data_new$Diesel <- Toyota_data_new$Toyota_data_Diesel
```


```{r dummy_vars_toyota_2}
Toyota_data_new = Toyota_data_new[,-7]
Toyota_data_new = cbind(Toyota_data_new,dummy(Toyota_data_new$Color, sep = "_"))
Toyota_data_new = Toyota_data_new[,-9]
Toyota_data_new
```


```{r sampling_toyota }
set.seed(999)
Split_dataset = sample(1:3, size = nrow(Toyota_data_new),prob = c(0.5,0.3,0.2), replace=TRUE)
training_data = Toyota_data_new[Split_dataset == 1,]
validation_data = Toyota_data_new[Split_dataset == 2,]
test_data = Toyota_data_new[Split_dataset == 3,]
```

a. Run a regression tree (RT) with the output variable Price and input variables
Age_08_04, KM, Fuel_Type, HP, Automatic, Doors, Quarterly_Tax, Mfg_Guarantee, Guarantee_Period, Airco, Automatic_Airco, CD Player, Powered_Windows, Sport_Model, and Tow_Bar.


```{r viz_toy_regression_tree}
regression_tree <- rpart(Price ~ Age_08_04 + KM + CNG + Diesel + Petrol + HP + Automatic + Doors + Quarterly_Tax + Mfr_Guarantee + Guarantee_Period + Airco + Automatic_airco + CD_Player + Powered_Windows + Sport_Model + Tow_Bar, data = training_data,  method = "anova")
prp(regression_tree, type = 1, extra = 1, under = TRUE, branch = 0, split.font = 1,cex =1 ,varlen = -10)
```

i. Which appear to be the three or four most important car specifications for predicting the carâ€™s price?

The regression tree shows that the four most important variables are: Age_08_04, HP , Automatic and KM.


ii. Compare the prediction errors of the training, validation, and test sets by examining their RMS error and by plotting the three boxplots. What is happening with the training set predictions? How does the predictive performance of the test set compare to the other two? Why does this occur?

The RMSE shown below are in the following order: training, validation, testing.
The training dataset has the lowest, test dataset second lowest and validation dataset the highest.


The distribution in the boxplots for all three datasets are very similar; however, validation and test dataset contains more outliers, where validation dataset has three of the farthest of all. As expected, training dataset because the regression tree used it.



iv. If we used the full tree instead of the best pruned tree to score the validation set, how would this affect the predictive performance for the validation set? (Hint: Does the full tree use the validation data?)

-----------------------------------------------------------------------------

Let us see the effect of turning the price variable into a categorical variable. First, create a new variable that categorizes price into 20 bins of equal counts. Now repartition the data keeping Binned Price instead of Price. Run a classification tree (CT) with the same set of input variables as in the RT, and with Binned Price as the output variable.

```{r binning_price}
Toyota_data_new$bin_price = as.factor(as.numeric(cut(Toyota_data_new$Price,20)))
Toyota_data_class <- Toyota_data_new[,-2]
```

```{r classification_split}
training_data_c <- Toyota_data_class[Split_dataset==1,] 
validation_data_c <- Toyota_data_class[Split_dataset==2,]
test_data_c <- Toyota_data_class[Split_dataset==3,]
training_data_c
```

```{r}
classification_tree <- rpart(bin_price ~ Age_08_04 + KM + CNG + Diesel + Petrol + HP + Automatic + Doors + Quarterly_Tax + Mfr_Guarantee + Guarantee_Period + Airco + Automatic_airco + CD_Player + Powered_Windows + Sport_Model + Tow_Bar , data = training_data_c, method = "class")

prp(classification_tree, type = 1, extra = 1, split.font = 1, varlen = -10, cex = 0.5)
```
## i) Compare the tree generated by the CT with the one generated by the RT. Are they different? (Look at structure, the top predictors, size of tree, etc.) Why?

The classification tree, seen below, has 7 nodes and 2 predictor in common as the regression tree. The 4 most important predictors are: Age_08_04, KM, Mfr_Guarantee and Powered_Windows.
The differences between the two regression trees are because the regression is based on average and classification is based on majority vote.


## ii. Predict the price, using the RT and the CT, of a used Toyota Corolla with the specifications listed in Table given in question.

```{r predictions1}
new_toyota_data <- data.frame(Age_08_04=77,CNG=0,Diesel=0,Petrol=1,KM=117000,HP=110,Automatic=0,Doors=5,Quarterly_Tax=100,Mfr_Guarantee=0,Guarantee_Period=3,Airco=1,Automatic_airco=0,CD_Player=0,Powered_Windows=0,Sport_Model=0,Tow_Bar=1)

#Predictions
pred.regression <- predict(regression_tree,new_toyota_data)
pred.classification <- predict(classification_tree,new_toyota_data,type="class") 

pred.regression
pred.classification

split <- strsplit(as.character(pred.classification),split = ",")
p1 <- as.numeric(substr(pred.classification[[1]][1],2,100))
p2 <- as.numeric(substr(pred.classification[[1]][2],1,10))
pred.c <- (p2+p1)/2
```

iii. Compare the predictions in terms of the predictors that were used, the magnitude of the difference between the two predictions, and the advantages and disadvantages of the two methods.

```{r reading_banks}
Banks<-read.xlsx("Banks.xlsx")
Banks
```


2.

```{r labelling_banks}
Banks$Financial.Condition<- factor(Banks$Financial.Condition,levels=c(0,1), labels=c("Strong","Weak")) 
Banks$Financial.Condition
```


```{r banks_modelling}
lr_model <- glm(Financial.Condition ~ `TotLns&Lses/Assets` + `TotExp/Assets`, data = Banks, family = "binomial")

summary(lr_model)


coef(lr_model)
exp(coef(lr_model))

```

a. Write the estimated equation that associates the financial condition of a bank with its two predictors in three formats:
i. The logit as a function of the predictors
  
$text{Logit(Financial Condition = weak)} = -14.188 + (9.173 * (TotLns&Lses/Assets)) + (79.964 * (TotExp/Assets))$

ii. The odds as a function of the predictors

$text{Odds(Financial Condition = weak)} = e ^ -14.188 + 9.173(TotLns&Lses/Assets) + 79.964(TotExp/Assets)$

iii. The probability as a function of the predictors

$ text{Probability (Financial Condition = weak)} = \frac {e ^ {-14.188 + 9.173(TotLns&Lses/Assets) + 79.964(TotExp/Assets)}} {1 + {e ^ {-14.188 + 9.173(TotLns&Lses/Assets) + 79.964(TotExp/Assets)}}$

b. Consider a new bank whose total loans and leases/assets ratio = 0.6 and total
expenses/assets ratio = 0.11. From your logistic regression model, estimate the following four quantities for this bank: the logit, the odds, the probability of being financially weak, and the classification of the bank.

```{r}


```
The Financial Condition is higher than 0.5, the cutoff value used, thus the new bank is considered to be successful.


c. The cutoff value of 0.5 is used in conjunction with the probability of being financially weak. Compute the threshold that should be used if we want to make a classification based on the odds of being financially weak, and the threshold for the corresponding logit.
d. Interpret the estimated coefficient for the total loans & leases to total assets ratio (TotLns&Lses/Assets) in terms of the odds of being financially weak.
e. When a bank that is in poor financial condition is misclassified as financially strong, the misclassification cost is much higher than when a financially strong bank is misclassified as weak. To minimize the expected cost of misclassification, should the cutoff value for classification (which is currently at 0.5) be increased or decreased?



```{r}

```



```{r}

```
