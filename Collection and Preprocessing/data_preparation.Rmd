---
title: "News data Preprocessing"
output: html_document
---

```{r setup, include=FALSE}
library(readr)
library(plyr)
library(dplyr)
```

## R Markdown

Creating combined dataset by including all companies news data. NYTimes Data:

```{r concatenating_files}

file_list <- list.files()
for (file in file_list){
       
  # if the merged dataset doesn't exist, create it
  if (!exists("dataset")){
    dataset <- read.table(file, header=TRUE, sep=",")
  }
   
  # if the merged dataset does exist, append to it
  if (exists("dataset")){
    temp_dataset <-read.table(file, header=TRUE, sep=",")
    dataset<-rbind(dataset, temp_dataset)
    rm(temp_dataset)
  }
 
}
final_df <- dataset
rm(dataset)

```


```{r preprocessing data}

final_df_new<- final_df
final_df_new$created_time<-as.Date(final_df$created_time,format="%Y-%m-%d")

company_data <-final_df_new %>% 
                  filter(news_desk == 'Business' & created_time >= '2008-08-08' & created_time <= '2016-07-01')%>% 
                  select(company_name,created_time,headline)


company_data<-ddply(company_data, .(company_name,created_time), summarise, headline=paste0(headline, collapse="; "))

levels(company_data$company_name)

write.csv(company_data, file = "/Users/manyaraman/Desktop/Comapny_Data.csv", row.names = FALSE)
```

Preprocessing and formatting Reddit data :

```{r reddit_news_data}

Combined_news<-read_csv('Combined_News_DJIA.csv')
Combined_news<-Combined_news[,-2]

for(i in colnames(Combined_news[,-1])){
Combined_news[[i]]<-str_sub(Combined_news[[i]], 2)
  }

Combined_news_final <- unite(Combined_news, com_headlines, Top1:Top25, sep = ";", remove = TRUE)

Reddit_news<-read_csv('RedditNews.csv')
Reddit_news<-ddply(Reddit_news, .(Date), summarise, News=paste0(News ,collapse="; "))

Reddit_news$News<-str_replace_all(Reddit_news$News,c("b'" = "", "b\"" = ""))

write.csv(Reddit_news, file = "/Users/manyaraman/Desktop/Combined_news_final_reddit_wknd.csv", row.names = FALSE)
```


